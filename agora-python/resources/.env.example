# Пример файла конфигурации для TranscriptionService
# Скопируйте этот файл в .env (в корне проекта) и настройте под свои нужды
# Команда: Copy-Item resources\.env.example .env

# ========================================
# Настройки сервера
# ========================================

# Порт для прослушивания gRPC сервера
SERVER_PORT=50051

# Адрес для прослушивания (по умолчанию все интерфейсы)
SERVER_HOST=[::]

# Максимальное количество worker потоков
SERVER_MAX_WORKERS=10

# ========================================
# Настройки ML модели
# ========================================

# Название модели
MODEL_NAME=Vikhrmodels/Borealis

# Использовать локальные файлы модели (true/false)
MODEL_LOCAL_FILES_ONLY=true

# Устройство для обработки (cuda, cpu)
MODEL_DEVICE=cuda

# Batch size для обработки
MODEL_BATCH_SIZE=32

# Целевая длительность чанка в секундах
MODEL_CHUNK_DURATION=30

# ========================================
# Настройки производительности
# ========================================

# Максимальный размер сообщения для отправки (200 MB)
GRPC_MAX_SEND_MESSAGE_LENGTH=209715200

# Максимальный размер сообщения для получения (200 MB)
GRPC_MAX_RECEIVE_MESSAGE_LENGTH=209715200

# ========================================
# Настройки логирования
# ========================================

# Уровень логирования (DEBUG, INFO, WARNING, ERROR, CRITICAL)
LOGGING_LEVEL=INFO

# Формат логов
LOGGING_FORMAT=%(asctime)s - %(name)s - %(levelname)s - %(message)s

# ========================================
# Дополнительные настройки
# ========================================

# Отключить онлайн-загрузку моделей (1 = отключено)
HF_HUB_OFFLINE=1
